{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rg29HPaZhfIv"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import multiprocessing\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seglearn\n",
    "from sys import getsizeof\n",
    "from scipy.stats import entropy, iqr, kurtosis\n",
    "from scipy.stats.stats import pearsonr\n",
    "from IPython.display import display\n",
    "from ipywidgets import IntProgress\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from scipy.fftpack import fft\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GncZPGZEqQ7F"
   },
   "outputs": [],
   "source": [
    "project_dir = \"~/School/bbdc/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NFvPWM4npCti"
   },
   "source": [
    "## Load trained labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LGT0d8EagiJ9"
   },
   "outputs": [],
   "source": [
    "labels = read_csv(project_dir+\"train/labels.train.csv\", header=None)\n",
    "labels.columns = [\"Subject\", \"Start\", \"End\", \"Action\"]\n",
    "print(labels.shape)\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SP5KIJhSgom0"
   },
   "outputs": [],
   "source": [
    "filenames = sorted(list(set([x.split(\".\")[0] for x in labels.Subject])))\n",
    "filenames_test = [\"s06t01\",\"s06t02\",\"s06t03\",\"s06t04\",\"s06t05\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-w2c0x4Fgfc"
   },
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    \"la-object-pick\": 0,\n",
    "    \"ra-object-pick\": 0,\n",
    "    \"la-object-carry\": 1,\n",
    "    \"ra-object-carry\": 1,\n",
    "    \"la-object-place\": 2,\n",
    "    \"ra-object-place\": 2,\n",
    "    \"la-object-switch-hands\": 3,\n",
    "    \"ra-object-switch-hands\": 3,\n",
    "    \"la-object-orient\": 4,\n",
    "    \"ra-object-orient\": 4,\n",
    "    \"la-nothing\": 5,\n",
    "    \"ra-nothing\": 5\n",
    "}\n",
    "inverted_label_mapping_left = {\n",
    "    0: \"la-object-pick\",\n",
    "    1: \"la-object-carry\",\n",
    "    2: \"la-object-place\",\n",
    "    3: \"la-object-switch-hands\",\n",
    "    4: \"la-object-orient\",\n",
    "    5: \"la-nothing\"\n",
    "}\n",
    "inverted_label_mapping_right = {\n",
    "    0: \"ra-object-pick\",\n",
    "    1: \"ra-object-carry\",\n",
    "    2: \"ra-object-place\",\n",
    "    3: \"ra-object-switch-hands\",\n",
    "    4: \"ra-object-orient\",\n",
    "    5: \"ra-nothing\"\n",
    "}\n",
    "emg_positions = [\"fa-o-t-r\",\"fa-i-t-r\",\"fa-i-b-r\",\"fa-o-b-r\",\"fa-o-t-l\",\"fa-i-t-l\",\"fa-i-b-l\",\"fa-o-b-l\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hx6TjrFFdRNZ"
   },
   "source": [
    "## Match the EMG measurement to the corresponding labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fwW-dXOpKUoP"
   },
   "source": [
    "### -     Overwrites the old .emg.csv files with new ones containing the action labels for all timestamps \n",
    "### -     Removes `55,885` rows that don't have a corresponding action label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JCLV5VlWc0D-"
   },
   "outputs": [],
   "source": [
    "f = IntProgress(min=0, max=len(filenames)-1) # instantiate the bar\n",
    "display(f) # display the bar\n",
    "\n",
    "for fname in filenames:\n",
    "    fname_base = fname.split(\".\")[0]\n",
    "    # if not fname_base == \"s01t01\":\n",
    "    #     break\n",
    "    fname = fname_base + \".emg.csv\"\n",
    "    print(fname, fname.split(\".\")[0])\n",
    "    emg_sample = read_csv(project_dir+\"train/emg/\"+fname)\n",
    "    print(\"found\",emg_sample.shape[0], \"measurements\")\n",
    "    actions_for_file = labels[labels.Subject.isin([fname_base+\".la\", \n",
    "                                                                                                 fname_base+\".ra\"])]\n",
    "\n",
    "    print(\"Found\", actions_for_file.shape[0], \"actions for file\") \n",
    "\n",
    "    actions_for_la_for_file = actions_for_file[actions_for_file.Subject == fname_base+\".la\"]\n",
    "    actions_for_ra_for_file = actions_for_file[actions_for_file.Subject == fname_base+\".ra\"]\n",
    "    print(\"l:\", actions_for_la_for_file.shape[0], \n",
    "                \"r:\", actions_for_ra_for_file.shape[0])\n",
    "\n",
    "    actions_la, actions_ra = [],[]\n",
    "\n",
    "    # Get the left actions for each time stamp\n",
    "    for i,label in actions_for_la_for_file.iterrows():\n",
    "        measurements_for_ith_label = emg_sample[emg_sample.ts < label.End][emg_sample.ts >= label.Start]\n",
    "        new_values = measurements_for_ith_label.shape[0]*[label.Action]\n",
    "        actions_la += new_values\n",
    "        # print(\"Left\",len(new_values), \"measurements\", \"for time\", label.End)\n",
    "    print(\"finished left going on right\")\n",
    "    # Get the right actions for each time stamp\n",
    "    for i,label in actions_for_ra_for_file.iterrows():\n",
    "        measurements_for_ith_label = emg_sample[emg_sample.ts < label.End][emg_sample.ts >= label.Start]\n",
    "        new_values = measurements_for_ith_label.shape[0]*[label.Action]\n",
    "        actions_ra += new_values\n",
    "        # print(\"Right\",len(new_values), \"measurements\", \"for time\", label.End)\n",
    "\n",
    "    print(\"Total\", \"Left:\", len(actions_la), \"Right:\", len(actions_ra))\n",
    "    if (len(actions_la)!=len(actions_ra)):\n",
    "        print(\"****** Left labels and Right labels not equal ********\")\n",
    "    print(\"No labels for\", emg_sample.shape[0]-len(actions_ra), \"samples\")\n",
    "    actions_la = pd.DataFrame(actions_la, columns=[\"la\"])\n",
    "    actions_ra = pd.DataFrame(actions_ra, columns=[\"ra\"])\n",
    "\n",
    "    new_file = pd.concat([emg_sample.iloc[:actions_la.shape[0]][:], actions_la, actions_ra], axis=1)\n",
    "    print(new_file.shape)\n",
    "    new_file.to_csv(project_dir+\"train/emg/\"+fname, index = False)\n",
    "    print(\"------ Saved new version ------\")\n",
    "    f.value += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k99m0NpckYCM"
   },
   "source": [
    "## Match the MoCap measurement to the corresponding labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZMWD8YCdkYCT"
   },
   "source": [
    "### -     Overwrites the old .mocap.csv files with new ones containing the action labels for all timestamps \n",
    "### -     Removes `X` rows that don't have a corresponding action label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "diti4NUwkYCU"
   },
   "outputs": [],
   "source": [
    "f = IntProgress(min=0, max=len(filenames)-1) # instantiate the bar\n",
    "display(f) # display the bar\n",
    "\n",
    "for fname in filenames:\n",
    "    fname_base = fname.split(\".\")[0]\n",
    "    # if not fname_base == \"s01t01\":\n",
    "    #     break\n",
    "    fname = fname_base + \".mocap.csv\"\n",
    "    print(fname, fname.split(\".\")[0])\n",
    "    mocap_sample = read_csv(project_dir+\"train/mocap/\"+fname)\n",
    "    mocap_sample = mocap_sample.interpolate()\n",
    "    print(\"found\",mocap_sample.shape[0], \"measurements\")\n",
    "    actions_for_file = labels[labels.Subject.isin([fname_base+\".la\", \n",
    "                                                                                                 fname_base+\".ra\"])]\n",
    "\n",
    "    print(\"Found\", actions_for_file.shape[0], \"actions for file\") \n",
    "\n",
    "    actions_for_la_for_file = actions_for_file[actions_for_file.Subject == fname_base+\".la\"]\n",
    "    actions_for_ra_for_file = actions_for_file[actions_for_file.Subject == fname_base+\".ra\"]\n",
    "    print(\"l:\", actions_for_la_for_file.shape[0], \n",
    "                \"r:\", actions_for_ra_for_file.shape[0])\n",
    "\n",
    "    actions_la, actions_ra = [],[]\n",
    "\n",
    "    # Get the left actions for each time stamp\n",
    "    for i,label in actions_for_la_for_file.iterrows():\n",
    "        measurements_for_ith_label = mocap_sample[mocap_sample.ts < label.End][mocap_sample.ts >= label.Start]\n",
    "        new_values = measurements_for_ith_label.shape[0]*[label.Action]\n",
    "        actions_la += new_values\n",
    "        # print(\"Left\",len(new_values), \"measurements\", \"for time\", label.End)\n",
    "    print(\"finished left going on right\")\n",
    "    # Get the right actions for each time stamp\n",
    "    for i,label in actions_for_ra_for_file.iterrows():\n",
    "        measurements_for_ith_label = mocap_sample[mocap_sample.ts < label.End][mocap_sample.ts >= label.Start]\n",
    "        new_values = measurements_for_ith_label.shape[0]*[label.Action]\n",
    "        actions_ra += new_values\n",
    "        # print(\"Right\",len(new_values), \"measurements\", \"for time\", label.End)\n",
    "\n",
    "    print(\"Total\", \"Left:\", len(actions_la), \"Right:\", len(actions_ra))\n",
    "    if (len(actions_la)!=len(actions_ra)):\n",
    "        print(\"****** Left labels and Right labels not equal ********\")\n",
    "    print(\"No labels for\", mocap_sample.shape[0]-len(actions_ra), \"samples\")\n",
    "    actions_la = pd.DataFrame(actions_la, columns=[\"la\"])\n",
    "    actions_ra = pd.DataFrame(actions_ra, columns=[\"ra\"])\n",
    "\n",
    "    new_file = pd.concat([mocap_sample.iloc[:actions_la.shape[0]][:], actions_la, actions_ra], axis=1)\n",
    "    print(new_file.shape)\n",
    "    new_file.to_csv(project_dir+\"train/mocap/\"+fname, index = False)\n",
    "    print(\"------ Saved new version ------\")\n",
    "    f.value += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eN2OjfZ59kA_"
   },
   "source": [
    "## Load all EMG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJTbFYwG9psH"
   },
   "outputs": [],
   "source": [
    "def load_all_emg_data(filenames,train=True):\n",
    "    emg_datasets = []\n",
    "    if train:\n",
    "        subdir = \"train/\"\n",
    "    else:\n",
    "        subdir = \"test/\"\n",
    "    for i in range(len(filenames)):\n",
    "        if (i * 100) // len(filenames) % 10 == 0:\n",
    "            print(str(i * 100 // len(filenames))+\"%\")\n",
    "        emg_datasets.append(pd.read_csv(project_dir+subdir+\"emg/\"+filenames[i]+\".emg.csv\"))\n",
    "\n",
    "    emg_df = pd.concat(emg_datasets, ignore_index=True)\n",
    "    print(emg_df.shape)\n",
    "    return emg_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1JeLckVQjz0h"
   },
   "source": [
    "## Load all MoCap data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xT13Qp35jz0k"
   },
   "outputs": [],
   "source": [
    "def load_all_mocap_data(filenames,train=True):\n",
    "    mocap_datasets = []\n",
    "    if train:\n",
    "        subdir = \"train/\"\n",
    "    else:\n",
    "        subdir = \"test/\"\n",
    "    for i in range(len(filenames)):\n",
    "        if (i * 100) // len(filenames) % 10 == 0:\n",
    "            print(str(i * 100 // len(filenames))+\"%\")\n",
    "        mocap_datasets.append(pd.read_csv(project_dir+subdir+\"mocap/\"+filenames[i]+\".mocap.csv\"))\n",
    "\n",
    "    mocap_df = pd.concat(mocap_datasets, ignore_index=True)\n",
    "    print(mocap_df.shape)\n",
    "    return mocap_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MDZRxeZtdB2J"
   },
   "source": [
    "## EMG measurements feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LFKr4EoCTQDM"
   },
   "source": [
    "### Features to be extrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "caWqdsCTTO4o"
   },
   "outputs": [],
   "source": [
    "def entropy1(labels, base=None):\n",
    "    value,counts = np.unique(labels, return_counts=True)\n",
    "    return entropy(counts, base=base)\n",
    "\n",
    "def minimum(inputs):\n",
    "     return inputs.min()\n",
    "\n",
    "def maximum(inputs):\n",
    "    return inputs.max()\n",
    "\n",
    "def min_max_diff(inputs):\n",
    "    return inputs.max() - inputs.min()\n",
    "\n",
    "def variance(inputs):\n",
    "    return inputs.std()\n",
    "\n",
    "def mAverage(inputs):\n",
    "    return inputs.mean()\n",
    "\n",
    "def root_mean_square(inputs):\n",
    "    return np.sqrt(np.mean(np.array(inputs)**2))\n",
    "\n",
    "def inter_quartile_range(inputs):\n",
    "    return iqr(inputs, axis=0)\n",
    "\n",
    "def third_quartile(inputs):\n",
    "    return np.percentile(inputs, 75, axis=0)\n",
    "\n",
    "def kurt(inputs):\n",
    "    return kurtosis(inputs)\n",
    "\n",
    "def mPearsonCorrelation(first, second):\n",
    "    if (len(first) < 2) or (len(second) < 2):\n",
    "        return 0\n",
    "    val = pearsonr(first, second)[0]\n",
    "    if np.isnan(val):\n",
    "        return 0.5\n",
    "    else:\n",
    "        return (val+1)/2\n",
    "features_to_extract = [entropy1,\n",
    "                     minimum,\n",
    "                     maximum,\n",
    "                     min_max_diff,\n",
    "                     variance,\n",
    "                     mAverage,\n",
    "                     root_mean_square,\n",
    "                     inter_quartile_range,\n",
    "                     third_quartile,\n",
    "                     kurt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yYNnigquIDdk"
   },
   "outputs": [],
   "source": [
    "def extract_features(emg_measures_with_labels, side=None):\n",
    "    extracted_features = []\n",
    "    label_mapped = None\n",
    "    if side:\n",
    "        x = emg_measures_with_labels[side]\n",
    "        label_mapped = label_mapping[x.iloc[0]]\n",
    "    for emg_position in emg_positions:\n",
    "        measurements = emg_measures_with_labels[emg_position]\n",
    "        for feature in features_to_extract:\n",
    "            value = feature(np.array(measurements))\n",
    "            extracted_features.append(value)\n",
    "    for i in range(len(emg_positions)):\n",
    "        for j in range(i+1, len(emg_positions)):\n",
    "            emg_position1 = emg_positions[i]\n",
    "            emg_position2 = emg_positions[j]\n",
    "            value = mPearsonCorrelation(emg_measures_with_labels[emg_position1], \n",
    "                                                                    emg_measures_with_labels[emg_position2])\n",
    "            extracted_features.append(value)\n",
    "    extracted_features.append(emg_measures_with_labels.shape[0])\n",
    "    return extracted_features, label_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CsdtDg29oHAZ"
   },
   "outputs": [],
   "source": [
    "def learn_model(X,y,n_splits=4,hidden_layer_sizes=(40,40),model=\"nn\"):\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    train_mses = []\n",
    "    test_mses = []\n",
    "    classifiers = []\n",
    "    alphas = np.linspace(0.00001, 1, n_splits)\n",
    "    index = 0\n",
    "    plot_label = \"\"\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train = X[train_index]\n",
    "        X_test = X[test_index]\n",
    "        y_train = y[train_index]\n",
    "        y_test = y[test_index]\n",
    "        if model == \"nn\":\n",
    "            clf = MLPClassifier(solver='lbfgs', alpha=alphas[index],hidden_layer_sizes=hidden_layer_sizes, random_state=1,max_iter=1000)\n",
    "            plot_label = \"Neural Network \" + str(hidden_layer_sizes)\n",
    "        elif model == \"svm\":\n",
    "            clf = SVC(gamma='auto')\n",
    "            plot_label = \"SVM\"\n",
    "        clf.fit(X_train, y_train)\n",
    "        classifiers.append(clf)\n",
    "        y_pred_train = clf.predict(X_train)\n",
    "        train_mse = accuracy_score(y_train, y_pred_train)\n",
    "        y_pred_test = clf.predict(X_test)\n",
    "        test_mse = accuracy_score(y_test, y_pred_test)\n",
    "        train_mses.append(train_mse)\n",
    "        test_mses.append(test_mse)\n",
    "        index += 1\n",
    "    plt.plot(train_mses, \"r\")\n",
    "    plt.plot(test_mses, \"y\")\n",
    "    plt.title(plot_label)\n",
    "    print(train_mses)\n",
    "    print(test_mses)\n",
    "    plt.show()\n",
    "    return classifiers[np.argmin(np.array(test_mse))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NtCUkcB0nXMg"
   },
   "outputs": [],
   "source": [
    "def extract_features_by_window(emg_measures_with_labels, train=True):\n",
    "    extracted_features = []\n",
    "\n",
    "    left_label_mapped, right_label_mapped = None, None\n",
    "    if train:\n",
    "        left_labels = list(emg_measures_with_labels[\"la\"])\n",
    "        right_labels = list(emg_measures_with_labels[\"ra\"])\n",
    "        left_label = max(left_labels,key=left_labels.count)\n",
    "        right_label = max(right_labels,key=right_labels.count)\n",
    "        left_label_mapped = label_mapping[left_label]\n",
    "        right_label_mapped = label_mapping[right_label]\n",
    "\n",
    "    for emg_position in emg_positions:\n",
    "        measurements = emg_measures_with_labels[emg_position]\n",
    "        for feature in features_to_extract:\n",
    "            value = feature(np.array(measurements))\n",
    "            extracted_features.append(value)\n",
    "\n",
    "    for i in range(len(emg_positions)):\n",
    "        for j in range(i+1, len(emg_positions)):\n",
    "            emg_position1 = emg_positions[i]\n",
    "            emg_position2 = emg_positions[j]\n",
    "            value = mPearsonCorrelation(emg_measures_with_labels[emg_position1], \n",
    "                                                                    emg_measures_with_labels[emg_position2])\n",
    "            extracted_features.append(value)\n",
    "\n",
    "    return extracted_features, left_label_mapped, right_label_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9RUUOawOT8w"
   },
   "outputs": [],
   "source": [
    "emg_df = load_all_emg_data(filenames=filenames)\n",
    "sys.getsizeof(emg_df)/1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uVQNWYRskWfh"
   },
   "outputs": [],
   "source": [
    "mocap_df = load_all_mocap_data(filenames=filenames)\n",
    "mocap_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C8YB4MIT8kY9"
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GdQlYum1v-mG"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 2)\n",
    "fig= plt.figure(figsize=(20.5,14.5))\n",
    "times = emg_df[\"ts\"].values\n",
    "new_reading = np.argwhere(times==0)\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "for i in range(8):\n",
    "    values = emg_df.iloc[:,i+1]\n",
    "    l = ax.figure.subplotpars.left\n",
    "    r = ax.figure.subplotpars.right\n",
    "    t = ax.figure.subplotpars.top\n",
    "    b = ax.figure.subplotpars.bottom\n",
    "    figw = float(20)/(r-l)\n",
    "    figh = float(8)/(t-b)\n",
    "    axs[i//2,i%2].figure.set_size_inches(figw, figh)\n",
    "    axs[i//2,i%2].set_title(emg_df.columns[i+1])\n",
    "    axs[i//2,i%2].get_xaxis().set_visible(False)\n",
    "    axs[i//2,i%2].get_yaxis().set_visible(False)\n",
    "\n",
    "    for j in new_reading:\n",
    "        axs[i//2,i%2].axvline(x=j,color='r')\n",
    "    axs[i//2,i%2].plot(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VNISQ8f4970m"
   },
   "source": [
    "# Without Window Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8q7w2w36aAT"
   },
   "source": [
    "## Extract features for left and right actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UvajgadAI6jE"
   },
   "outputs": [],
   "source": [
    "\n",
    "left_change_indexes = emg_df[\"la\"].ne(emg_df[\"la\"].shift())[emg_df[\"la\"].ne(emg_df[\"la\"].shift()) == True].index.values\n",
    "right_change_indexes = emg_df[\"ra\"].ne(emg_df[\"ra\"].shift())[emg_df[\"ra\"].ne(emg_df[\"ra\"].shift()) == True].index.values\n",
    "print(\"Found\", len(left_change_indexes), \"left action changes and\", len(right_change_indexes), \"right action changes\")\n",
    "\n",
    "left_action_features = []\n",
    "right_action_features = []\n",
    "left_action_labels = []\n",
    "right_action_labels = []\n",
    "left_action_timestamp = []\n",
    "right_action_timestamp = []\n",
    "\n",
    "f = IntProgress(min=0, max=len(left_change_indexes)-1) # instantiate the bar\n",
    "display(f) # display the bar\n",
    "\n",
    "# Extract features from measurements with the same left action label\n",
    "for i in range(len(left_change_indexes)):\n",
    "    f.value += 1\n",
    "    start_index = left_change_indexes[i]\n",
    "    if (i == len(left_change_indexes)-1):\n",
    "        end_index = emg_df.shape[0]-1\n",
    "    else:\n",
    "        end_index = left_change_indexes[i+1]\n",
    "    left_action_timestamp.append([emg_df.iloc[start_index][\"ts\"], emg_df.iloc[end_index][\"ts\"]])\n",
    "    extracted_features, label_mapped = extract_features(emg_df.iloc[start_index:end_index], \"la\")\n",
    "    left_action_features.append(extracted_features)\n",
    "    left_action_labels.append(label_mapped)\n",
    "\n",
    "print(\"Finished extracting features for left actions going on to right\")\n",
    "\n",
    "f1 = IntProgress(min=0, max=len(right_change_indexes)-1) # instantiate the bar\n",
    "display(f1) # display the bar\n",
    "# Extract features from measurements with the same right action label\n",
    "for i in range(len(right_change_indexes)):\n",
    "    f1.value += 1\n",
    "    start_index = right_change_indexes[i]\n",
    "    if (i == len(right_change_indexes)-1):\n",
    "        end_index = emg_df.shape[0]-1\n",
    "    else:\n",
    "        end_index = right_change_indexes[i+1]\n",
    "    right_action_timestamp.append([emg_df.iloc[start_index][\"ts\"], emg_df.iloc[end_index][\"ts\"]])\n",
    "    extracted_features, label_mapped = extract_features(emg_df.iloc[start_index:end_index], \"ra\")\n",
    "    right_action_features.append(extracted_features)\n",
    "    right_action_labels.append(label_mapped)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0htBNw86iEG"
   },
   "source": [
    "## Parse extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1gJdVfrzd_OF"
   },
   "outputs": [],
   "source": [
    "print(len(left_action_features[0]))\n",
    "\n",
    "header = [[\"entropy1-\"+x,\n",
    "                \"minimum-\"+x,\n",
    "                \"maximum-\"+x,\n",
    "                \"min_max_diff-\"+x,\n",
    "                \"variance-\"+x,\n",
    "                \"mAverage-\"+x,\n",
    "                \"root_mean_square-\"+x,\n",
    "                \"inter_quartile_range-\"+x,\n",
    "                \"third_quartile-\"+x,\n",
    "                \"kurt-\"+x] for x in emg_positions]\n",
    "\n",
    "header = list(np.array(header).flatten())\n",
    "header += [\"corr\"+str(x+1) for x in range(28)]\n",
    "header.append(\"size\")\n",
    "\n",
    "left_action_features = pd.DataFrame(left_action_features, columns=header)\n",
    "right_action_features = pd.DataFrame(right_action_features, columns=header)\n",
    "left_action_labels = pd.DataFrame(left_action_labels, columns=[\"labels\"])\n",
    "right_action_labels = pd.DataFrame(right_action_labels, columns=[\"labels\"])\n",
    "left_action_timestamp = pd.DataFrame(left_action_timestamp, columns=[\"start_time\", \"end_time\"])\n",
    "right_action_timestamp = pd.DataFrame(right_action_timestamp, columns=[\"start_time\", \"end_time\"])\n",
    "\n",
    "display(left_action_features)\n",
    "display(right_action_features)\n",
    "display(left_action_labels)\n",
    "display(right_action_labels)\n",
    "display(left_action_timestamp)\n",
    "display(right_action_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z99cjOu5h2uI"
   },
   "outputs": [],
   "source": [
    "action_values = left_action_labels.index[left_action_labels.labels==3]\n",
    "plt.plot(left_action_features.loc[action_values,\"min_max_diff-fa-o-t-r\"],\"b.\")\n",
    "plt.plot(left_action_features.loc[action_values,\"min_max_diff-fa-o-t-l\"],\"r.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UzctWEw2lPHd"
   },
   "outputs": [],
   "source": [
    "true_labels_left = pd.DataFrame(left_action_labels[\"labels\"].map(inverted_label_mapping_left))\n",
    "true_labels_right = pd.DataFrame(right_action_labels[\"labels\"].map(inverted_label_mapping_right))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6XPTkmE6lnOB"
   },
   "source": [
    "### Offset negative values and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-m_FsEKC9oFO"
   },
   "outputs": [],
   "source": [
    "for columnName, column in left_action_features.iteritems():\n",
    "    if any(column<0):\n",
    "        column += abs(min(column))\n",
    "    left_action_features[columnName] = column / column.max()\n",
    "\n",
    "for columnName, column in right_action_features.iteritems():\n",
    "    if any(column<0):\n",
    "        column += abs(min(column))\n",
    "    right_action_features[columnName] = column / column.max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D8fepsAqqgx-"
   },
   "source": [
    "### Output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mpajxWiQmZgs"
   },
   "outputs": [],
   "source": [
    "pd.concat([left_action_features,left_action_labels,true_labels_left,left_action_timestamp], axis=1).to_csv(project_dir+\"train/left_extracted.csv\",index=None)\n",
    "pd.concat([right_action_features,right_action_labels,true_labels_left,right_action_timestamp], axis=1).to_csv(project_dir+\"train/right_extracted.csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pg9nZdCTt3Gg"
   },
   "source": [
    "## Train models after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PyP5F3owDu3S"
   },
   "outputs": [],
   "source": [
    "pca = PCA(.9)\n",
    "pca_left_action_features = pca.fit_transform(left_action_features)\n",
    "pca_right_action_features = pca.fit_transform(right_action_features)\n",
    "\n",
    "X = pca_left_action_features\n",
    "y = left_action_labels.values\n",
    "left_classifier_nn = learn_model(X,y,n_splits=8,hidden_layer_sizes=(20))\n",
    "left_classifier_svm = learn_model(X,y,model=\"svm\")\n",
    "\n",
    "X = pca_right_action_features\n",
    "y = right_action_labels.values\n",
    "right_classifier_nn = learn_model(X,y,n_splits=8,hidden_layer_sizes=(20))\n",
    "right_classifier_svm = learn_model(X,y,model=\"svm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hmXwTri-yWV6"
   },
   "source": [
    "# With Window Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hGjZYtB9wwIG"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "action_features_by_window = []\n",
    "left_action_labels_by_window = []\n",
    "right_action_labels_by_window = []\n",
    "timestamp_by_window = []\n",
    "\n",
    "N = emg_df.shape[0]\n",
    "frequency = 600\n",
    "window_size = int(0.5 * frequency) # 0.5 second\n",
    "indexes = list(range(0,N,window_size))\n",
    "f = IntProgress(min=0, max=len(indexes)-1) # instantiate the bar\n",
    "display(f) # display the bar\n",
    "\n",
    "# Extract features from N/window_size measurements with size window_size\n",
    "for i in range(len(indexes)):\n",
    "    f.value += 1\n",
    "    start_index = indexes[i]\n",
    "    if (i == len(indexes)-1):\n",
    "        end_index = N-1\n",
    "    else:\n",
    "        end_index = indexes[i+1]\n",
    "    timestamp_by_window.append([emg_df.iloc[start_index][\"ts\"], emg_df.iloc[end_index][\"ts\"]])\n",
    "    extracted_features, left_label_mapped, right_label_mapped = extract_features_by_window(emg_df.iloc[start_index:end_index+1])\n",
    "    action_features_by_window.append(extracted_features)\n",
    "    left_action_labels_by_window.append(left_label_mapped)\n",
    "    right_action_labels_by_window.append(right_label_mapped)\n",
    "\n",
    "\n",
    "print(len(action_features_by_window), len(action_features_by_window[0]))\n",
    "print(len(timestamp_by_window), len(timestamp_by_window[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RJfTeLz9GXEl"
   },
   "outputs": [],
   "source": [
    "print(type(action_features_by_window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DxW-lEgQzFQj"
   },
   "outputs": [],
   "source": [
    "print(len(action_features_by_window), len(action_features_by_window[0]))\n",
    "print(len(timestamp_by_window), len(timestamp_by_window[0]))\n",
    "header = [[\"entropy1-\"+x,\n",
    "                \"minimum-\"+x,\n",
    "                \"maximum-\"+x,\n",
    "                \"min_max_diff-\"+x,\n",
    "                \"variance-\"+x,\n",
    "                \"mAverage-\"+x,\n",
    "                \"root_mean_square-\"+x,\n",
    "                \"inter_quartile_range-\"+x,\n",
    "                \"third_quartile-\"+x,\n",
    "                \"kurt-\"+x] for x in emg_positions]\n",
    "\n",
    "header = list(np.array(header).flatten())\n",
    "header += [\"corr\"+str(x+1) for x in range(28)]\n",
    "print(len(header))\n",
    "\n",
    "action_features_by_window = pd.DataFrame(action_features_by_window, columns=header)\n",
    "left_action_labels_by_window = pd.DataFrame(left_action_labels_by_window, columns=[\"labels\"])\n",
    "right_action_labels_by_window = pd.DataFrame(right_action_labels_by_window, columns=[\"labels\"])\n",
    "timestamp_by_window = pd.DataFrame(timestamp_by_window, columns=[\"start_time\", \"end_time\"])\n",
    "\n",
    "display(action_features_by_window)\n",
    "display(left_action_labels)\n",
    "display(right_action_labels)\n",
    "display(timestamp_by_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xHUUbUkn8xiY"
   },
   "outputs": [],
   "source": [
    "true_labels_left_by_window = pd.DataFrame(left_action_labels[\"labels\"].map(inverted_label_mapping_left))\n",
    "true_labels_right_by_window = pd.DataFrame(right_action_labels[\"labels\"].map(inverted_label_mapping_right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWp__jN0zHvZ"
   },
   "outputs": [],
   "source": [
    "pd.concat([action_features_by_window, left_action_labels_by_window, right_action_labels_by_window, true_labels_left_by_window, true_labels_right_by_window, timestamp_by_window], axis=1).to_csv(project_dir+\"train/emg_feature_extracted_by_window_300.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-kt8co8p90oS"
   },
   "outputs": [],
   "source": [
    "for columnName, column in action_features_by_window.iteritems():\n",
    "    if any(column<0):\n",
    "        column += abs(min(column))\n",
    "    action_features_by_window[columnName] = column / column.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GH0WwVTr9Q_D"
   },
   "outputs": [],
   "source": [
    "pca = PCA(.9,)\n",
    "pca_action_features_by_window = pca.fit_transform(action_features_by_window)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.singular_values_)\n",
    "print(pca_action_features_by_window.shape)\n",
    "X = pca_action_features_by_window\n",
    "y = left_action_labels_by_window.values\n",
    "left_classifier_nn = learn_model(X,y,n_splits=8,hidden_layer_sizes=(20))\n",
    "left_classifier_svm = learn_model(X,y,model=\"svm\")\n",
    "y = right_action_labels_by_window.values\n",
    "right_classifier_nn = learn_model(X,y,n_splits=8,hidden_layer_sizes=(20))\n",
    "right_classifier_svm = learn_model(X,y,model=\"svm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ePe8DXRoKt8R"
   },
   "source": [
    "# Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s60ufrOs0NG8"
   },
   "outputs": [],
   "source": [
    "emg_df_test = load_all_emg_data(filenames=filenames_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r_ZDsuQB-is_"
   },
   "source": [
    "## Autocatically set the action of the first parts of each subject to `la-nothing` and `ra-nothing`\n",
    "This is because the measurements always start by `nothing` actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FaIxgIjxtTVw"
   },
   "outputs": [],
   "source": [
    "first_rows = [round(random.uniform(4.5,8.5)*600) for x in range(5)]\n",
    "zero_indexes = emg_df_test.index[emg_df_test[\"ts\"]==0].to_list()\n",
    "\n",
    "la_column = [\"la-nothing\"]*first_rows[0] + [np.nan]*(zero_indexes[1]-first_rows[0]-zero_indexes[0]) + \\\n",
    "                        [\"la-nothing\"]*first_rows[1] + [np.nan]*(zero_indexes[2]-first_rows[1]-zero_indexes[1]) + \\\n",
    "                        [\"la-nothing\"]*first_rows[2] + [np.nan]*(zero_indexes[3]-first_rows[2]-zero_indexes[2]) + \\\n",
    "                        [\"la-nothing\"]*first_rows[3] + [np.nan]*(zero_indexes[4]-first_rows[3]-zero_indexes[3]) + \\\n",
    "                        [\"la-nothing\"]*first_rows[4] + [np.nan]*(emg_df_test.shape[0]-first_rows[4]-zero_indexes[4])\n",
    "\n",
    "ra_column = [\"ra-nothing\"]*first_rows[0] + [np.nan]*(zero_indexes[1]-first_rows[0]-zero_indexes[0]) + \\\n",
    "                        [\"ra-nothing\"]*first_rows[1] + [np.nan]*(zero_indexes[2]-first_rows[1]-zero_indexes[1]) + \\\n",
    "                        [\"ra-nothing\"]*first_rows[2] + [np.nan]*(zero_indexes[3]-first_rows[2]-zero_indexes[2]) + \\\n",
    "                        [\"ra-nothing\"]*first_rows[3] + [np.nan]*(zero_indexes[4]-first_rows[3]-zero_indexes[3]) + \\\n",
    "                        [\"ra-nothing\"]*first_rows[4] + [np.nan]*(emg_df_test.shape[0]-first_rows[4]-zero_indexes[4])\n",
    "print(len(la_column),len(ra_column))\n",
    "emg_df_test[\"la\"] = la_column\n",
    "emg_df_test[\"ra\"] = ra_column\n",
    "# for i in range(len(first_rows)):\n",
    "#     emg_df_test[\"la\"][zero_indexes[i]:first_rows[i]] = \"la-nothing\"\n",
    "#     emg_df_test[\"ra\"][zero_indexes[i]:first_rows[i]] = \"ra-nothing\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eUAIoOUG_Rjl"
   },
   "source": [
    "## Remove rows already assigned nothing actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jGkKVBh0y3-X"
   },
   "outputs": [],
   "source": [
    "emg_df_test_no_first_rows = emg_df_test[emg_df_test[\"la\"].isnull()].reindex()\n",
    "emg_df_test_no_first_rows = emg_df_test_no_first_rows.drop([\"la\", \"ra\"],axis=1)\n",
    "display(emg_df_test_no_first_rows.head())\n",
    "ind = 0\n",
    "step = 0\n",
    "indexes_new = []\n",
    "while ind < emg_df_test_no_first_rows.shape[0]:\n",
    "    step = round(random.uniform(1.5,3.5)*600)\n",
    "    ind = min(ind + step, emg_df_test_no_first_rows.shape[0])\n",
    "\n",
    "    indexes_new.append(ind)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dw9aQDP9_cMI"
   },
   "source": [
    "## Extract features for test measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Job9K4DdgV0S"
   },
   "outputs": [],
   "source": [
    "\n",
    "extracted_features_test = []\n",
    "test_time_stamps = []\n",
    "f = IntProgress(min=0, max=len(indexes_new)-2) # instantiate the bar\n",
    "display(f) # display the bar\n",
    "\n",
    "# Extract features from measurements with the same left action label\n",
    "for i in range(len(indexes_new)-1):\n",
    "    f.value += 1\n",
    "    start_index = indexes_new[i]\n",
    "    end_index = indexes_new[i+1]\n",
    "    test_time_stamps.append([emg_df_test_no_first_rows.iloc[start_index][\"ts\"], emg_df_test_no_first_rows.iloc[end_index-1][\"ts\"]])\n",
    "    extracted_features, label_mapped = extract_features(emg_df_test_no_first_rows.iloc[start_index:end_index])\n",
    "    extracted_features_test.append(extracted_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SsWhQET0_lyD"
   },
   "source": [
    "## Parse extracted features for test measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BEMmB1f0rQag"
   },
   "outputs": [],
   "source": [
    "print(len(extracted_features_test[0]))\n",
    "\n",
    "header = [[\"entropy1-\"+x,\n",
    "                \"minimum-\"+x,\n",
    "                \"maximum-\"+x,\n",
    "                \"min_max_diff-\"+x,\n",
    "                \"variance-\"+x,\n",
    "                \"mAverage-\"+x,\n",
    "                \"root_mean_square-\"+x,\n",
    "                \"inter_quartile_range-\"+x,\n",
    "                \"third_quartile-\"+x,\n",
    "                \"kurt-\"+x] for x in emg_positions]\n",
    "\n",
    "header = list(np.array(header).flatten())\n",
    "header += [\"corr\"+str(x+1) for x in range(28)]\n",
    "header.append(\"size\")\n",
    "print(len(header))\n",
    "\n",
    "extracted_features_test = pd.DataFrame(extracted_features_test, columns=header)\n",
    "test_time_stamps = pd.DataFrame(test_time_stamps, columns=[\"start_time\", \"end_time\"])\n",
    "\n",
    "display(extracted_features_test)\n",
    "display(test_time_stamps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RuTNQpWg_rOC"
   },
   "source": [
    "## Normalize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qBoqf345sVdV"
   },
   "outputs": [],
   "source": [
    "for columnName, column in extracted_features_test.iteritems():\n",
    "    if any(column<0):\n",
    "        column += abs(min(column))\n",
    "    extracted_features_test[columnName] = column / column.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fGSyOY4__vYX"
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "icOXmcU0-6S4"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=16)\n",
    "pca_extracted_features_test = pca.fit_transform(extracted_features_test)\n",
    "left_prediction_test = left_classifier_nn.predict(pca_extracted_features_test)\n",
    "right_prediction_test = right_classifier_nn.predict(pca_extracted_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tCZ8jYqQDgfC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oP-CDVj2AXRF"
   },
   "outputs": [],
   "source": [
    "true_labels_left_test = pd.DataFrame(pd.Series(left_prediction_test).map(inverted_label_mapping_left))\n",
    "true_labels_right_test = pd.DataFrame(pd.Series(right_prediction_test).map(inverted_label_mapping_right))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ZZs6N56ACb9"
   },
   "source": [
    "## Parse Predictions For Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RSwd6_C2A18l"
   },
   "outputs": [],
   "source": [
    "la_output_test = pd.concat([test_time_stamps, true_labels_left_test],axis=1)\n",
    "ra_output_test = pd.concat([test_time_stamps, true_labels_right_test],axis=1)\n",
    "pd.concat([la_output_test, ra_output_test],axis=0).to_csv(project_dir+\"test/labels.test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D9A1ikx4DjMq"
   },
   "outputs": [],
   "source": [
    "final_list_pred = []\n",
    "final_list_pred_time = []\n",
    "before = 0\n",
    "final_list_pred.append(left_prediction_test[before])\n",
    "final_list_pred_time.append(list(test_time_stamps.iloc[before]))\n",
    "\n",
    "for i in range(1, len(left_prediction_test)):\n",
    "    if left_prediction_test[i] == left_prediction_test[before]:\n",
    "        final_list_pred_time[len(final_list_pred_time)-1][1] = list(test_time_stamps.iloc[i])[1]\n",
    "    else:\n",
    "        final_list_pred.append(left_prediction_test[i])\n",
    "        final_list_pred_time.append(list(test_time_stamps.iloc[i]))\n",
    "    before = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ECZmIOlUFjrd"
   },
   "outputs": [],
   "source": [
    "ff = pd.DataFrame(final_list_pred_time,columns=[\"start_time\",\"end_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EyDQtyOlGCDw"
   },
   "outputs": [],
   "source": [
    "ff[\"action\"] = final_list_pred\n",
    "ff[\"action\"] = ff[\"action\"].map(inverted_label_mapping_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ivDdbMwLS_F"
   },
   "outputs": [],
   "source": [
    "final_list_pred = []\n",
    "final_list_pred_time = []\n",
    "before = 0\n",
    "final_list_pred.append(right_prediction_test[before])\n",
    "final_list_pred_time.append(list(test_time_stamps.iloc[before]))\n",
    "\n",
    "for i in range(1, len(right_prediction_test)):\n",
    "    if right_prediction_test[i] == right_prediction_test[before]:\n",
    "        final_list_pred_time[len(final_list_pred_time)-1][1] = list(test_time_stamps.iloc[i])[1]\n",
    "    else:\n",
    "        final_list_pred.append(right_prediction_test[i])\n",
    "        final_list_pred_time.append(list(test_time_stamps.iloc[i]))\n",
    "    before = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HkrK9dLRLkKs"
   },
   "outputs": [],
   "source": [
    "ff_right = pd.DataFrame(final_list_pred_time,columns=[\"start_time\",\"end_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fsa3X_egLkKx"
   },
   "outputs": [],
   "source": [
    "ff_right[\"action\"] = final_list_pred\n",
    "ff_right[\"action\"] = ff_right[\"action\"].map(inverted_label_mapping_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qJvx8PgsLt1l"
   },
   "outputs": [],
   "source": [
    "pd.concat([ff, ff_right],axis=0).to_csv(project_dir+\"test/labels_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6s7TQKScMghA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "fwW-dXOpKUoP"
   ],
   "name": "BBDC_2020.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
